<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Krishna Somandepalli, PhD | Google DeepMind</title>
    <style>
    :root {
            /* BRANDING COLORS */
            --accent-color: #003366; /* Deep Navy (Primary) */
            --link-hover: #800020;   /* ADD THIS LINE: Burgundy for hover */
            
            /* ... keep your other existing variables below ... */
            --bg-color: #ffffff;
            --text-color: #333333;
            --sidebar-bg: #f8f9fa; 
            --border-color: #e9ecef;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            margin: 0;
            padding: 0;
            color: var(--text-color);
            line-height: 1.6;
        }

        /* LAYOUT: Two Columns (Sidebar + Main) */
        .wrapper {
            display: flex;
            min-height: 100vh;
            flex-direction: column;
        }

        /* SIDEBAR (Left) */
        .sidebar {
            background-color: var(--sidebar-bg);
            padding: 3rem 2rem;
            text-align: center;
            border-bottom: 1px solid var(--border-color);
        }

        .profile-pic {
            width: 180px;
            height: 180px;
            border-radius: 50%;
            object-fit: cover;
            border: 4px solid #fff;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            margin-bottom: 1.5rem;
        }

        .sidebar h1 {
            font-size: 1.4rem;
            margin: 0.5rem 0;
            color: var(--accent-color);
            font-weight: 700;
        }

        .sidebar h2 {
            font-size: 1rem;
            font-weight: 500;
            color: #555;
            margin: 0 0 1.5rem 0;
            line-height: 1.4;
        }

        .contact-links a {
            display: block;
            margin-bottom: 0.5rem;
            color: var(--accent-color);
            text-decoration: none;
            font-weight: 600;
            font-size: 0.9rem;
        }

        .contact-links a:hover { text-decoration: underline; }

        /* MAIN CONTENT (Right) */
        .main-content {
            padding: 3rem 2rem;
            max-width: 800px;
        }
/* MODERN LINK STYLING (The Burgundy Update) */
        .main-content a {
            color: var(--text-color); /* Keeps text dark/readable */
            text-decoration: none;
            font-weight: 600;
            border-bottom: 1px solid rgba(0, 51, 102, 0.3); /* Subtle navy underline */
            transition: all 0.2s ease;
        }

        .main-content a:hover {
            color: var(--link-hover); /* Burgundy Text */
            border-bottom: 2px solid var(--link-hover); /* Burgundy Underline */
            background-color: rgba(128, 0, 32, 0.05); /* Very faint burgundy highlight */
        }

        /* Keep sidebar links clean (No underline by default) */
        .contact-links a {
            border-bottom: none; 
        }

        .contact-links a:hover { 
            color: var(--link-hover);
            text-decoration: underline; 
            background-color: transparent; /* No background box for sidebar */
        }
        
        h3 {
            color: var(--accent-color);
            border-bottom: 2px solid var(--border-color);
            padding-bottom: 0.5rem;
            margin-top: 2.5rem;
            font-size: 1.4rem;
        }
        
        h3:first-child { margin-top: 0; }

        p { margin-bottom: 1.5rem; text-align: justify; }

        /* RESEARCH AREA STYLING */
        .research-area {
            margin-bottom: 2rem;
            padding-bottom: 2rem;
            border-bottom: 1px dashed var(--border-color);
        }
        .research-area:last-child { border-bottom: none; }

        .area-title {
            font-weight: 700;
            color: #222;
            font-size: 1.2rem;
            margin-bottom: 0.5rem;
        }
        
        .area-tags {
            font-size: 0.85rem;
            color: var(--accent-color);
            margin-bottom: 0.75rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.05em;
        }

        /* Footer */
        .mobile-footer {
            text-align: center;
            padding: 2rem;
            font-size: 0.8rem;
            color: #888;
            margin-top: 2rem;
            border-top: 1px solid var(--border-color);
        }

        /* DESKTOP VIEW */
        @media (min-width: 900px) {
            .wrapper { flex-direction: row; }
            .sidebar {
                width: 320px;
                flex-shrink: 0;
                text-align: left;
                height: 100vh;
                position: sticky;
                top: 0;
                border-right: 1px solid var(--border-color);
                border-bottom: none;
                display: flex;
                flex-direction: column;
                justify-content: center;
            }
            .profile-pic {
                width: 160px;
                height: 160px;
                margin: 0 auto 1.5rem auto;
                display: block;
            }
            .sidebar h1, .sidebar h2, .contact-links { text-align: center; }
            .main-content { padding: 4rem 5rem; overflow-y: auto; }
        }
    </style>
</head>
<body>

<div class="wrapper">
    
    <aside class="sidebar">
        <img src="IMG_2799.jpeg" alt="Krishna Somandepalli" class="profile-pic">
        
        <h1>Krishna Somandepalli</h1>
        <h2>Senior Research Engineer<br>Google DeepMind</h2>
        
        <div class="contact-links">
            <a href="mailto:krishna.somandepalli@gmail.com">Email Me</a>
            <a href="https://scholar.google.com/citations?hl=en&user=ih4OLKoAAAAJ&view_op=list_works" target="_blank">Google Scholar</a>
            <a href="https://www.linkedin.com/in/krishna-somandepalli-38827912" target="_blank">LinkedIn</a>
            <a href="https://sail.usc.edu/~somandep/" target="_blank">Academic Archive</a>
        </div>
    </aside>

    <main class="main-content">
        
        <h3>About Me</h3>
        <p>
            I am a <strong>Senior Research Engineer</strong> at <strong>Google DeepMind</strong> in New York City, where I develop AI systems that learn from multimodal, real-world data. My work integrates vision, audio, language, and structured signals to model and generate rich human-centered content.
        </p>
        <p>
            Previously, I was with Google Research and received my PhD in Electrical and Computer Engineering from University of Southern California (<a href="https://sail.usc.edu/" target="_blank">Signal Analysis and Interpretation Lab</a>). My academic background is rooted in <strong>multimodal representation learning</strong> and <strong>affective computing</strong>—bridging the gap between raw signals and human-level understanding.
        </p>
        <p>
            Prior to my doctoral studies, I earned my Master's degree in Electrical Engineering from <strong>UC Santa Barbara</strong> and served as a Jr. Research Scientist at <strong>NYU Langone Medical Center</strong>. There, I developed statistical models to analyze functional brain networks using fMRI data, an experience that grounded my later work in decoding complex human signals.
        </p>
        <p>
            Across all my work—from foundational models to recent AI agents—I'm driven by the goal of building AI that is technically robust, meaningful, and useful to society.
        </p>

        <h3>Research Areas</h3>
        
        <div class="research-area">
            <div class="area-title">Multimodal & Agentic AI</div>
            <div class="area-tags">Gemini 2.5 • Reasoning • Long-Context</div>
            <div>
                I focus on advancing the reasoning and agentic capabilities of large-scale systems to model and understand multimodal content. My work on <a href="https://arxiv.org/abs/2507.06261" target="_blank"><strong>Gemini 2.5</strong></a> family of model centers on perceiving complex environments, reason over long contexts, and act autonomously, pushing the boundaries of what foundational models can achieve in real-world applications.
            </div>
        </div>

        <div class="research-area">
            <div class="area-title">Generative Media & Expressivity</div>
            <div class="area-tags">VideoPoet • Versatile Diffusion • Patents</div>
            <div>
                Generating content is not enough; we must enable fine-grained control. I build architectures for high-fidelity video and audio generation: notably, <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ih4OLKoAAAAJ&sortby=pubdate&citation_for_view=ih4OLKoAAAAJ:abG-DnoFyZgC" target="_blank"><strong>VideoPoet</strong></a> (Best Paper Award, CVPR 2024) and <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ih4OLKoAAAAJ&sortby=pubdate&citation_for_view=ih4OLKoAAAAJ:dfsIfKJdRG4C" target="_blank"><strong>Versatile Diffusion</strong></a> (NeurIPS 2024), with a focus on expressivity and temporal coherence. I hold multiple patents that enable <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ih4OLKoAAAAJ&sortby=pubdate&citation_for_view=ih4OLKoAAAAJ:nb7KW1ujOQ8C" target="_blank">rich captioning</a> technologies, <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ih4OLKoAAAAJ&sortby=pubdate&citation_for_view=ih4OLKoAAAAJ:1sJd4Hv_s6UC" target="_blank">task-agnostic training</a> for multimodal diffusion, and <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ih4OLKoAAAAJ&sortby=pubdate&citation_for_view=ih4OLKoAAAAJ:abG-DnoFyZgC" target="_blank">cross-modal emotion-understanding</a> systems.            
            </div>
        </div>

        <div class="research-area">
            <div class="area-title">Computational Media Intelligence</div>
            <div class="area-tags">Longitudinal Analysis • Event Structure • Scale</div>
            <div>
                Understanding complex media content requires more than pixel-level processing; it requires analyzing structure over time. I develop systems for the <strong>large-scale longitudinal analysis</strong> of media content, establishing the foundational frameworks for <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ih4OLKoAAAAJ&citation_for_view=ih4OLKoAAAAJ:ufrVoPGSRksC" target="_blank"><strong>Computational Media Intelligence</strong></a>. This includes patented methods for <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ih4OLKoAAAAJ&sortby=pubdate&citation_for_view=ih4OLKoAAAAJ:u_35RYKgDlwC" target="_blank">unsupervised event discovery</a>, enabling machines to parse narrative arcs across thousands of hours of video—work <a href="https://www.youtube.com/watch?v=2EDiHryKwwE" target="_blank">featured by Google Research</a>.
            </div>
        </div>

        <div class="mobile-footer">
            &copy; 2025 Krishna Somandepalli. Built in NYC.
        </div>

    </main>
</div>

</body>
</html>
